{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718f54c3-6d20-4ed0-9752-e1751e6b84e5",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/nicholasmetherall/digital-earth-pacific-macblue-activities/blob/main/attachments/images/DE_Pacific_banner.JPG?raw=true\" width=\"900\"/>\n",
    "\n",
    "Figure 1.1.a. Jupyter environment + Python notebooks\n",
    "\n",
    "# Digital Earth Pacific Notebook 1 prepare postcard and load data to csv\n",
    "\n",
    "The objective of this notebook is to prepare a geomad postcard for your AOI (masking, scaling and loading additional band ratios and spectral indices) and sampling all the datasets into a csv based on your training data geodataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887498ee",
   "metadata": {},
   "source": [
    "## Step 1.1: Configure the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bda661-ae78-4f82-82b3-e68a5aa32d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import box\n",
    "from pyproj import CRS \n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from ipyleaflet import basemaps\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "from odc.stac import load\n",
    "from pystac.client import Client\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from utils import scale, do_prediction, calculate_band_indices, apply_masks, threshold_calc_land, threshold_calc_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c3e96-d81a-4a01-b638-20cde81d98f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined variable for title and version\n",
    "\n",
    "# Enter your initials\n",
    "initials = \"agl\"\n",
    "\n",
    "# Enter your site name\n",
    "site = \"bootless\"\n",
    "\n",
    "# Date\n",
    "date = datetime.now()\n",
    "\n",
    "# Make a clean version string\n",
    "version = f\"{initials}-{site}-{date.strftime('%d%m%Y')}\"\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb62e5e-32bf-4ccd-8ac1-8e7c95102d5a",
   "metadata": {},
   "source": [
    "## Step 1.2: Configure STAC access and search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ca2ac-2484-4d63-8f54-e7370dd8764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = \"https://stac.digitalearthpacific.org\"\n",
    "client = Client.open(catalog)\n",
    "\n",
    "mspc_catalogue = \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n",
    "dem_collection = \"cop-dem-glo-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f010cdf-e7ae-4d07-94fb-d33de1758634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Use training data bounds\n",
    "\n",
    "training = gpd.read_file(\"training-data/bootless_bay.geojson\")\n",
    "training = training.to_crs(\"EPSG:4326\")\n",
    "min_lon, min_lat, max_lon, max_lat = training.total_bounds\n",
    "\n",
    "bbox = [min_lon, min_lat, max_lon, max_lat]\n",
    "\n",
    "min_lon, min_lat, max_lon, max_lat = bbox\n",
    "bbox_polygon = Polygon([\n",
    "    (min_lon, min_lat),\n",
    "    (max_lon, min_lat),\n",
    "    (max_lon, max_lat),\n",
    "    (min_lon, max_lat),\n",
    "    (min_lon, min_lat) # Close the polygon\n",
    "])\n",
    "\n",
    "# TODO: configure colours...\n",
    "training.explore(column=\"observed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7f3ef-b395-4d6f-a2cc-6f10bb29ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use bounding box\n",
    "\n",
    "# min_lon = 147.23859958846435\n",
    "# min_lat = -9.544064327324529\n",
    "# max_lon = 147.31182409906984\n",
    "# max_lat = -9.477718193563604\n",
    "\n",
    "# bbox = (min_lon, min_lat, max_lon, max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1174aa0-ed65-4eaf-bc8f-e77c4775140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_stac_client = pystac_client.Client.open(mspc_catalogue)\n",
    "\n",
    "search = dem_stac_client.search(\n",
    "    collections=[dem_collection],\n",
    "    bbox=bbox,\n",
    "    max_items=1\n",
    ")\n",
    "\n",
    "item = next(search.get_items())\n",
    "print(f\"STAC item ID: {item.id}\")\n",
    "\n",
    "# Get signed asset URL\n",
    "asset_href = planetary_computer.sign(item.assets[\"data\"].href)\n",
    "print(asset_href)\n",
    "\n",
    "# # Mask elevation:\n",
    "bbox_polygon = box(*bbox)\n",
    "dem = rioxarray.open_rasterio(asset_href).squeeze()\n",
    "dem = dem.rio.clip([bbox_polygon], crs=\"EPSG:4326\", drop=True)\n",
    "elevation_threshold: float = 10.0\n",
    "masked = dem.where(dem <= elevation_threshold)\n",
    "masked = masked.compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a580b2-f7cf-444c-bcd9-fb87088c4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = \"2024\"\n",
    "\n",
    "items = client.search(\n",
    "    collections=[\"dep_s2_geomad\"],\n",
    "    datetime=datetime,\n",
    "    bbox=bbox\n",
    ").item_collection()\n",
    "\n",
    "print(f\"Found {len(items)} items in for {datetime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514c9ea-39b8-44bc-a68f-33e632a7c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\n",
    "    items,\n",
    "    measurements=[\n",
    "        \"nir\",\n",
    "        \"red\",\n",
    "        \"blue\",\n",
    "        \"green\",\n",
    "        \"emad\",\n",
    "        \"smad\",\n",
    "        \"bcmad\",\n",
    "        \"count\",\n",
    "        \"green\",\n",
    "        \"nir08\",\n",
    "        \"nir09\",\n",
    "        \"swir16\",\n",
    "        \"swir22\",\n",
    "        \"coastal\",\n",
    "        \"rededge1\",\n",
    "        \"rededge2\",\n",
    "        \"rededge3\",\n",
    "    ],\n",
    "    crs=\"EPSG:3832\",\n",
    "    bbox=bbox,\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    "    groupby=\"solar_day\",\n",
    ")\n",
    "\n",
    "scaled = (data.where(data != 0) * 0.0001).clip(0, 1)\n",
    "\n",
    "# Load into memory\n",
    "scaled = scaled.compute().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate band ratios and indices\n",
    "\n",
    "# Modified Normalised Difference Water Index (MNDWI)\n",
    "scaled[\"mndwi\"] = (scaled[\"green\"] - scaled[\"swir16\"]) / (scaled[\"green\"] + scaled[\"swir16\"])\n",
    "\n",
    "# Normalised Difference Turbidity Index (NDTI)\n",
    "scaled[\"ndti\"] = (scaled[\"red\"] - scaled[\"green\"]) / (scaled[\"red\"] + scaled[\"green\"])\n",
    "\n",
    "# coastal aerosol index\n",
    "scaled[\"cai\"] = (scaled[\"coastal\"] - scaled[\"blue\"]) / (\n",
    "    scaled[\"coastal\"] + scaled[\"blue\"]\n",
    ")\n",
    "# vegetation index (NDVI)\n",
    "scaled[\"ndvi\"] = (scaled[\"nir\"] - scaled[\"red\"]) / (\n",
    "    scaled[\"nir\"] + scaled[\"red\"]\n",
    ")\n",
    "# enhanced vegetation index\n",
    "scaled[\"evi\"] = (2.5 * scaled[\"nir\"] - scaled[\"red\"]) / (\n",
    "    scaled[\"nir\"] + (6 * scaled[\"red\"]) - (7.5 * scaled[\"blue\"]) + 1\n",
    ")\n",
    "# soil adjusted vegetation index\n",
    "scaled[\"savi\"] = (scaled[\"nir\"] - scaled[\"red\"]) / (\n",
    "    scaled[\"nir\"] + scaled[\"red\"]\n",
    ")\n",
    "# water index (NDWI)\n",
    "scaled[\"ndwi\"] = (\n",
    "    (scaled[\"green\"] - scaled[\"nir\"])\n",
    "    / (scaled[\"green\"] + scaled[\"nir\"] + 0.428)\n",
    "    * (1 + 0.428)\n",
    ")\n",
    "# blue to green ratio\n",
    "scaled[\"b_g\"] = (scaled[\"blue\"]) / (scaled[\"green\"])\n",
    "# blue to red ratio\n",
    "scaled[\"b_r\"] = (scaled[\"blue\"]) / (scaled[\"red\"])\n",
    "# max chlorophlyll index (MCI)\n",
    "scaled[\"mci\"] = (scaled[\"nir\"]) / (scaled[\"rededge1\"])\n",
    "# normalised difference chlorophyll index (NDCI)\n",
    "scaled[\"ndci\"] = (scaled[\"rededge1\"] - scaled[\"red\"]) / (\n",
    "    scaled[\"rededge1\"] + scaled[\"red\"]\n",
    ")\n",
    "# Natural log of blue/green\n",
    "scaled[\"ln_bg\"] = np.log(scaled.blue / scaled.green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2f67e-3d0c-4af0-8ff5-265ff1946408",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the site we are working on\n",
    "scaled.odc.explore(vmin=0, vmax=0.3, bands=[\"red\", \"green\", \"blue\"], crs=\"EPSG:3832\", name=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccfec6-bc85-48a4-83eb-a7c2db3b1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moderate land mask\n",
    "MNDWI_THRESHOLD = -0.2\n",
    "mndwi_mask = scaled.mndwi > MNDWI_THRESHOLD\n",
    "\n",
    "mndwi_mask.odc.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06436300-924b-41c2-b7ec-f0f3dd404d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_bg = scaled['ln_bg'].values.flatten()  # flatten in case it's multi-dimensional\n",
    "# Remove NaNs if present\n",
    "ln_bg = ln_bg[~np.isnan(ln_bg)]\n",
    "# Calculate mean and std\n",
    "mean = ln_bg.mean()\n",
    "std = ln_bg.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep ocean mask\n",
    "ln_bg_mask = scaled[\"ln_bg\"] < 0\n",
    "\n",
    "ln_bg_mask.odc.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1978471-ad95-4d42-b33e-289647e7cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_masks)\n",
    "elevation_mask = masked.rio.write_crs(\"EPSG:3832\")\n",
    "print('elevation', elevation_mask.rio.crs)\n",
    "print('land', mndwi_mask.rio.crs)\n",
    "print('deep-sea', ln_bg_mask.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elevation mask is having issues\n",
    "all_masks = mndwi_mask & ln_bg_mask #& elevation_mask\n",
    "all_masks = all_masks.rio.write_crs(\"EPSG:3832\") # Use .rio.reproject\n",
    "\n",
    "centroid = scaled.odc.geobox.geographic_extent.centroid.coords[0][::-1]\n",
    "m = folium.Map(location=centroid, zoom_start=14)\n",
    "\n",
    "scaled.odc.to_rgba(bands=[\"red\", \"green\", \"blue\"], vmin=0, vmax=0.3).odc.add_to(m, name=\"RGB\")\n",
    "mndwi_mask.where(mndwi_mask == 0).odc.add_to(m, name=\"MNDWI Mask\", vmin=0, vmax=1)\n",
    "# ndti_mask.where(ndti_mask == 0).odc.add_to(m, name=\"NDTI Mask\", vmin=0, vmax=1)\n",
    "ln_bg_mask.where(ln_bg_mask == 0).odc.add_to(m, name=\"ln_bg Mask\", vmin=0, vmax=1)\n",
    "# all_masks.where(all_masks == 0).odc.add_to(m, name=\"All Masks\", vmin=0, vmax=1)\n",
    "all_masks.odc.add_to(m, name=\"All Masks\", vmin=0, vmax=1) \n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the mask, and view the masked region\n",
    "\n",
    "masked = scaled.where(all_masks)\n",
    "masked.odc.explore(\n",
    "    vmin=0, vmax=0.3, bands=[\"red\", \"green\", \"blue\"], name=f\"{site}-masked\", tiles=basemaps.OpenStreetMap.Mapnik  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b4340-0375-4e76-a228-44843530483b",
   "metadata": {},
   "source": [
    "### GLCM texture analysis\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 9\n",
    "LEVELS = 32\n",
    "\n",
    "# Input\n",
    "max = masked.blue.max().values\n",
    "min = masked.blue.min().values\n",
    "# Scale to 0-LEVELS for GLCM\n",
    "img = ((masked.blue - min) / (max - min) * (LEVELS - 1)).clip(0, LEVELS - 1).values.astype(np.uint8)\n",
    "\n",
    "# Extract overlapping windows\n",
    "patches = sliding_window_view(img, (WINDOW_SIZE, WINDOW_SIZE))\n",
    "# Shape: (rows, cols, win_y, win_x)\n",
    "\n",
    "# Your patch function\n",
    "def glcm_features(patch):\n",
    "    glcm = graycomatrix(\n",
    "        patch,\n",
    "        distances=[1],\n",
    "        angles=[0],\n",
    "        levels=LEVELS,\n",
    "        symmetric=True,\n",
    "        normed=True\n",
    "    )\n",
    "    out = np.empty(7, dtype=np.float32)\n",
    "    out[0] = graycoprops(glcm, \"contrast\")[0, 0]\n",
    "    out[1] = graycoprops(glcm, \"homogeneity\")[0, 0]\n",
    "    out[2] = graycoprops(glcm, \"energy\")[0, 0]\n",
    "    out[3] = graycoprops(glcm, \"ASM\")[0, 0]\n",
    "    out[4] = graycoprops(glcm, \"correlation\")[0, 0]\n",
    "    out[5] = graycoprops(glcm, \"mean\")[0, 0]\n",
    "\n",
    "            \n",
    "            # glcm_p = glcm[:, :, 0, 0]\n",
    "            # entropy[i, j] = -np.sum(glcm_p * np.log2(glcm_p + 1e-10))\n",
    "    \n",
    "    glcm_p = glcm[:, :, 0, 0]\n",
    "    out[6] = -np.sum(glcm_p * np.log2(glcm_p + 1e-10))\n",
    "    return out\n",
    "\n",
    "# Use apply_ufunc to vectorize over (row, col) dimensions\n",
    "result = xr.apply_ufunc(\n",
    "    glcm_features,\n",
    "    xr.DataArray(patches, dims=[\"y\", \"x\", \"win_y\", \"win_x\"]),\n",
    "    input_core_dims=[[\"win_y\", \"win_x\"]],\n",
    "    output_core_dims=[[\"feature\"]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[np.float32]\n",
    ")\n",
    "\n",
    "# Add coordinates & names\n",
    "pad = WINDOW_SIZE - 1\n",
    "result = result.assign_coords({\n",
    "    \"y\": masked.y[: -pad],\n",
    "    \"x\": masked.x[: -pad],\n",
    "    \"feature\": [\"contrast\", \"homogeneity\", \"energy\", \"ASM\", \"correlation\", \"mean\", \"entropy\"]\n",
    "})\n",
    "\n",
    "result_bands = result.to_dataset(dim=\"feature\")\n",
    "\n",
    "# Combine with original\n",
    "masked_plus = masked.copy()\n",
    "masked_plus = masked_plus.assign(result_bands)\n",
    "\n",
    "masked_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-apply the mask\n",
    "masked_plus = masked_plus.where(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c07169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_plus.correlation.odc.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457a1dd-9cbb-4704-b3ed-a6008cd51509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use .rio.to_raster() with driver=\"COG\"\n",
    "# output_filename = f\"{version}_prediction.tif\"\n",
    "\n",
    "\n",
    "# masked_plus.rio.to_raster(\n",
    "#     output_filename,\n",
    "#     driver=\"COG\",\n",
    "#     overwrite=True,        \n",
    "#     tiled=True,            \n",
    "# )\n",
    "\n",
    "# print(f\"GeoTIFF exported successfully to: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd17e13-a9d8-4c1a-9f4f-37caea2ca87e",
   "metadata": {},
   "source": [
    "### Postcard csv\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c58091-c716-40fd-9007-8ff22bfbe631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject training data to the GeoMAD CRS and convert to xarray\n",
    "training_reprojected = training.to_crs(masked_plus.odc.crs)\n",
    "training_da = training_reprojected.assign(\n",
    "    x=training_reprojected.geometry.x, y=training_reprojected.geometry.y\n",
    ").to_xarray()\n",
    "\n",
    "# Extract training values from the masked dataset\n",
    "training_values = (\n",
    "    masked_plus.sel(training_da[[\"x\", \"y\"]], method=\"nearest\")\n",
    "    .squeeze()\n",
    "    .compute()\n",
    "    .to_pandas()\n",
    ")\n",
    "training_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d13b52-bdfa-4709-ace8-8bae982060f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the training data with the extracted values and remove unnecessary columns\n",
    "training_array = pd.concat([training[\"cc_id\"], training_values], axis=1)\n",
    "\n",
    "# Drop rows where there was no data available\n",
    "training_array = training_array.dropna()\n",
    "\n",
    "# Preview our resulting training array\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the training data to a CSV file\n",
    "training_array.to_csv(f\"training-data/{version}-training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f55cf-4829-4eb6-9862-a92374b46255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
