{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718f54c3-6d20-4ed0-9752-e1751e6b84e5",
   "metadata": {},
   "source": [
    "# Machine Learning for Seagrass Extent Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bda661-ae78-4f82-82b3-e68a5aa32d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac.client import Client\n",
    "from odc.stac import load\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "from utils import scale, apply_masks, do_prediction, calculate_band_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb62e5e-32bf-4ccd-8ac1-8e7c95102d5a",
   "metadata": {},
   "source": [
    "## Loading Sentinel-2 GeoMAD\n",
    "\n",
    "Load data, then create band indices and mask out areas we don't want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ca2ac-2484-4d63-8f54-e7370dd8764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = \"https://stac.digitalearthpacific.org\"\n",
    "client = Client.open(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829aeb9-7288-4980-990f-5c4368dc7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ba Estuary\n",
    "bbox = [177.51971, -17.49416, 177.68452, -17.34430]\n",
    "datetime=\"2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a580b2-f7cf-444c-bcd9-fb87088c4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = client.search(\n",
    "    collections=[\"dep_s2_geomad\"], datetime=datetime, bbox=bbox\n",
    ").item_collection()\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514c9ea-39b8-44bc-a68f-33e632a7c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\n",
    "    items,\n",
    "    bbox=bbox,\n",
    "    measurements=[\n",
    "        \"nir\",\n",
    "        \"red\",\n",
    "        \"blue\",\n",
    "        \"green\",\n",
    "        \"emad\",\n",
    "        \"smad\",\n",
    "        \"bcmad\",\n",
    "        \"count\",\n",
    "        \"green\",\n",
    "        \"nir08\",\n",
    "        \"nir09\",\n",
    "        \"swir16\",\n",
    "        \"swir22\",\n",
    "        \"coastal\",\n",
    "        \"rededge1\",\n",
    "        \"rededge2\",\n",
    "        \"rededge3\",\n",
    "    ],\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccfec6-bc85-48a4-83eb-a7c2db3b1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scale(data)\n",
    "indices = calculate_band_indices(scaled_data)\n",
    "\n",
    "# TODO: split masks into separate functions\n",
    "masked_data = apply_masks(scaled_data)\n",
    "\n",
    "masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_data.odc.explore(bands=[\"red\", \"green\", \"blue\"], vmin=0, vmax=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0dcf1d",
   "metadata": {},
   "source": [
    "## Run predictions over our region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c857c-96be-4446-a8ac-87265e16dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"models/model-geomad-joined-data-rf-04032025.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a45c5e-dcc1-480a-82f1-83d2f34f321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_da = do_prediction(masked_data, model).astype(np.float32)\n",
    "predicted_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b0264-703e-4141-99c8-978fb835463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    [1, \"sediment\", \"#8c8c8c\"],\n",
    "    [2, \"sand\", \"#fedd24\"],\n",
    "    [3, \"rubble\", \"#f8ffb4\"],\n",
    "    [4, \"seagrass\", \"#6df7dc\"],\n",
    "    [5, \"seaweed\", \"#b9df6f\"],\n",
    "    [6, \"coral\", \"#a011c3\"],\n",
    "    [7, \"rock\", \"#804600\"],\n",
    "    [8, \"deeps\", \"#011b61\"],\n",
    "    [9, \"mangrove\", \"#086a39\"],\n",
    "    [10, \"land\", \"#00FFFFFF\"],\n",
    "]\n",
    "\n",
    "values_list = [c[0] for c in classes]\n",
    "color_list = [c[2] for c in classes]\n",
    "\n",
    "# Build a listed colormap.\n",
    "c_map = colors.ListedColormap(color_list)\n",
    "bounds = values_list + [14]\n",
    "norm = colors.BoundaryNorm(bounds, c_map.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156916b-3364-43d2-a674-0c2c69bf180c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "da.odc.explore(cmap=c_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db6a76-2043-46d4-a301-78fc0a8d301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_da.odc.write_cog(\"predictions/predicted_ba_estuary_joined_data_postcard_04032025.tiff\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223af22-de3d-4f5f-b358-c0c9d56feb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = gpd.read_file(\"testing-data/utanglang_postcard.geojson\")\n",
    "test_data.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90801a-ab61-4dd6-ac06-dafb15bdd311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First transform the training points to the same CRS as the data\n",
    "test = test_data.to_crs(postcard.odc.geobox.crs)\n",
    "# Next get the X and Y values out of the point geometries\n",
    "training_da = test.assign(x=test.geometry.x, y=test.geometry.y).to_xarray()\n",
    "# Now we can use the x and y values (lon, lat) to extract values from the median composite\n",
    "training_values = (\n",
    "    postcard.sel(training_da[[\"x\", \"y\"]], method=\"nearest\").squeeze().compute().to_pandas()\n",
    ")\n",
    "len(training_values)\n",
    "\n",
    "# Join the training data with the extracted values and remove unnecessary columns\n",
    "training_array = pd.concat([test[\"observed_id\"], training_values], axis=1)\n",
    "training_array = training_array.drop(\n",
    "    columns=[\n",
    "        \"y\",\n",
    "        \"x\",\n",
    "        \"spatial_ref\",\n",
    "    ]\n",
    ")\n",
    "# # Drop rows where there was no data available\n",
    "# training_array = training_array.dropna()\n",
    "# Preview our resulting training array\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454d068-58f8-4ce0-96bb-5c4e4df71031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the training data with the extracted values and remove unnecessary columns\n",
    "training_array = pd.concat([test[\"observed_id\"], training_values], axis=1)\n",
    "training_array = training_array.drop(\n",
    "    columns=[\n",
    "        \"y\",\n",
    "        \"x\",\n",
    "        \"spatial_ref\",\n",
    "    ]\n",
    ")\n",
    "# # Drop rows where there was no data available\n",
    "# training_array = training_array.dropna()\n",
    "# Preview our resulting training array\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405b021-1b2a-449c-8198-6bdd19ba39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_da.dtype)  # Check the dtype of your DataArray\n",
    "predicted_da = predicted_da.astype('float32')  # Convert to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6edd0f3-792d-440d-9c33-1112489e10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_array), len(test))  # Check the lengths of both arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777edafd-3a1c-41b9-9cd2-e79d11683917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(42)\n",
    "training_array = np.random.rand(100, 5)\n",
    "test = pd.DataFrame({\"observed_id\": np.random.choice([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 100)})\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_array, test.observed_id, test_size=0.9, random_state=42)\n",
    "\n",
    "# Replace None values with a default value, e.g., 0 or the most frequent value\n",
    "y_train = y_train.fillna(0)  # or y_train.fillna(y_train.mode()[0])\n",
    "y_test = y_test.fillna(0)    # Ensure y_test also has no None values\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Train your model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "plt.figure(figsize=(12, 10))  # Adjust width and height for larger plot\n",
    "cm_display.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b48448-6f12-4564-b784-667f0225866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a488ab-abb8-42f5-a0e2-345551a491f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5337b-42ef-4826-ac71-5be38322d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# report = classification_report(true_labels, predicted_labels, target_names=class_labels)\n",
    "# print(report)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['sediment', 'sand', 'rubble', 'seagrass', 'seaweed', 'coral', 'rock', 'deeps', 'mangrove', 'land'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acd5fc-4438-4319-ad10-46cca578354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique labels in y_test:\", np.unique(y_test))\n",
    "print(\"Unique labels in y_pred:\", np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7287ae-0c8b-49a4-b84e-3987b150a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of y_test:\", len(y_test))\n",
    "print(\"Length of y_pred:\", len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c8109-7f0e-4d15-9676-9fcedcb0b784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
