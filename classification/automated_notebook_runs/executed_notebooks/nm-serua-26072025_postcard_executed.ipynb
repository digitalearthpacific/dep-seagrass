{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f53421a",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [7]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf42426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T00:09:16.270867Z",
     "iopub.status.busy": "2025-07-27T00:09:16.270068Z",
     "iopub.status.idle": "2025-07-27T00:09:16.280059Z",
     "shell.execute_reply": "2025-07-27T00:09:16.279196Z"
    },
    "papermill": {
     "duration": 0.019531,
     "end_time": "2025-07-27T00:09:16.281490",
     "exception": false,
     "start_time": "2025-07-27T00:09:16.261959",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_geojson_path = \"training-data/postcards/nm-serua-26072025_postcard.geojson\"\n",
    "output_csv_path = \"automated_notebook_runs/sampled_data_csvs/nm-serua-26072025_postcard_sampled_data.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f54c3-6d20-4ed0-9752-e1751e6b84e5",
   "metadata": {
    "papermill": {
     "duration": 0.006532,
     "end_time": "2025-07-27T00:09:16.295140",
     "exception": false,
     "start_time": "2025-07-27T00:09:16.288608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://github.com/nicholasmetherall/digital-earth-pacific-macblue-activities/blob/main/attachments/images/DE_Pacific_banner.JPG?raw=true\" width=\"900\"/>\n",
    "\n",
    "Figure 1.1.a. Jupyter environment + Python notebooks\n",
    "\n",
    "# Digital Earth Pacific Notebook 1 prepare postcard and load data to csv\n",
    "\n",
    "The objective of this notebook is to prepare a geomad postcard for your AOI (masking, scaling and loading additional band ratios and spectral indices) and sampling all the datasets into a csv based on your training data geodataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35a7253-a309-45c0-9ce7-451abcab34e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T00:09:16.309799Z",
     "iopub.status.busy": "2025-07-27T00:09:16.309262Z",
     "iopub.status.idle": "2025-07-27T00:09:16.313571Z",
     "shell.execute_reply": "2025-07-27T00:09:16.312747Z"
    },
    "papermill": {
     "duration": 0.013347,
     "end_time": "2025-07-27T00:09:16.314959",
     "exception": false,
     "start_time": "2025-07-27T00:09:16.301612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is for papermill parameters. DO NOT CHANGE THE VARIABLE NAMES.\n",
    "# Default values for manual execution (papermill will override these)\n",
    "input_geojson_path = None\n",
    "output_csv_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887498ee",
   "metadata": {
    "papermill": {
     "duration": 0.00713,
     "end_time": "2025-07-27T00:09:16.328940",
     "exception": false,
     "start_time": "2025-07-27T00:09:16.321810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1.1: Configure the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bda661-ae78-4f82-82b3-e68a5aa32d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T00:09:16.346053Z",
     "iopub.status.busy": "2025-07-27T00:09:16.345125Z",
     "iopub.status.idle": "2025-07-27T00:09:19.021947Z",
     "shell.execute_reply": "2025-07-27T00:09:19.021011Z"
    },
    "papermill": {
     "duration": 2.687625,
     "end_time": "2025-07-27T00:09:19.023653",
     "exception": false,
     "start_time": "2025-07-27T00:09:16.336028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import box\n",
    "from pyproj import CRS \n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from ipyleaflet import basemaps\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import pystac_client\n",
    "from dask.distributed import Client as DaskClient\n",
    "from odc.stac import load, configure_s3_access\n",
    "import planetary_computer\n",
    "from odc.stac import load\n",
    "from pystac.client import Client\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from utils import load_data, scale, calculate_band_indices, apply_mask, mask_land, mask_deeps, mask_elevation, all_masks, glcm_features, do_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2edc9da-3387-495f-b7bc-5e3210259076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T00:09:19.039417Z",
     "iopub.status.busy": "2025-07-27T00:09:19.038514Z",
     "iopub.status.idle": "2025-07-27T00:09:19.089316Z",
     "shell.execute_reply": "2025-07-27T00:09:19.088412Z"
    },
    "papermill": {
     "duration": 0.060104,
     "end_time": "2025-07-27T00:09:19.090994",
     "exception": false,
     "start_time": "2025-07-27T00:09:19.030890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload scripts and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2c3e96-d81a-4a01-b638-20cde81d98f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T00:09:19.106233Z",
     "iopub.status.busy": "2025-07-27T00:09:19.105620Z",
     "iopub.status.idle": "2025-07-27T00:09:19.151244Z",
     "shell.execute_reply": "2025-07-27T00:09:19.150343Z"
    },
    "papermill": {
     "duration": 0.054573,
     "end_time": "2025-07-27T00:09:19.152543",
     "exception": false,
     "start_time": "2025-07-27T00:09:19.097970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm-serua_2-27072025\n"
     ]
    }
   ],
   "source": [
    "# Predefined variable for title and version\n",
    "\n",
    "# Enter your initials\n",
    "initials = \"nm\"\n",
    "\n",
    "# Enter your site name\n",
    "site = \"serua_2\"\n",
    "\n",
    "# Date\n",
    "date = datetime.now()\n",
    "\n",
    "# Make a clean version string\n",
    "version = f\"{initials}-{site}-{date.strftime('%d%m%Y')}\"\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb62e5e-32bf-4ccd-8ac1-8e7c95102d5a",
   "metadata": {
    "papermill": {
     "duration": 0.006828,
     "end_time": "2025-07-27T00:09:19.166718",
     "exception": false,
     "start_time": "2025-07-27T00:09:19.159890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1.2: Configure STAC access and search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975ca2ac-2484-4d63-8f54-e7370dd8764e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T00:09:19.182189Z",
     "iopub.status.busy": "2025-07-27T00:09:19.181611Z",
     "iopub.status.idle": "2025-07-27T00:09:19.259929Z",
     "shell.execute_reply": "2025-07-27T00:09:19.259019Z"
    },
    "papermill": {
     "duration": 0.088003,
     "end_time": "2025-07-27T00:09:19.261506",
     "exception": false,
     "start_time": "2025-07-27T00:09:19.173503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = \"https://stac.digitalearthpacific.org\"\n",
    "client = Client.open(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa088063",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f010cdf-e7ae-4d07-94fb-d33de1758634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T00:09:19.277432Z",
     "iopub.status.busy": "2025-07-27T00:09:19.276884Z",
     "iopub.status.idle": "2025-07-27T00:09:20.231580Z",
     "shell.execute_reply": "2025-07-27T00:09:20.230310Z"
    },
    "papermill": {
     "duration": 0.963824,
     "end_time": "2025-07-27T00:09:20.232796",
     "exception": true,
     "start_time": "2025-07-27T00:09:19.268972",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "None: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_geojson_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m training \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mto_crs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m min_lon, min_lat, max_lon, max_lat \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mtotal_bounds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/geopandas/io/file.py:317\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m             filename \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/geopandas/io/file.py:577\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[0;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    574\u001b[0m     )\n\u001b[1;32m    575\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pyogrio/geopandas.py:275\u001b[0m, in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpa\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pyogrio/raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:1293\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:232\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDataSourceError\u001b[0m: None: No such file or directory"
     ]
    }
   ],
   "source": [
    "training = gpd.read_file(input_geojson_path)\n",
    "training = training.to_crs(\"EPSG:4326\")\n",
    "min_lon, min_lat, max_lon, max_lat = training.total_bounds\n",
    "\n",
    "bbox = [min_lon, min_lat, max_lon, max_lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a580b2-f7cf-444c-bcd9-fb87088c4f3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime = \"2024\"\n",
    "\n",
    "items = client.search(\n",
    "    collections=[\"dep_s2_geomad\"],\n",
    "    datetime=datetime,\n",
    "    bbox=bbox\n",
    ").item_collection()\n",
    "\n",
    "print(f\"Found {len(items)} items in for {datetime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2abf4-e303-44bd-9747-e03419a42da9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "measurements = [\"nir\", \"red\", \"blue\", \"green\", \"emad\", \"smad\", \"bcmad\", \"green\", \"nir08\", \"nir09\", \"swir16\", \"swir22\", \"coastal\", \"rededge1\", \"rededge2\", \"rededge3\"]\n",
    "data = load_data(\n",
    "    items,\n",
    "    measurements,\n",
    "    bbox,\n",
    ")\n",
    "    \n",
    "# Now you can use the 'data' variable\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea9480-1232-4e9d-b70e-a87a37242135",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dask_client = DaskClient(n_workers=1, threads_per_worker=16, memory_limit='16GB')\n",
    "configure_s3_access(cloud_defaults=True, requester_pays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514c9ea-39b8-44bc-a68f-33e632a7c648",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled = scale(data)\n",
    "scaled = scaled.compute().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b19a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore the site we are working on\n",
    "scaled.odc.explore(vmin=0, vmax=0.3, bands=[\"red\", \"green\", \"blue\"], crs=\"EPSG:3832\", name=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ed81c-1e16-4efc-8485-9ff4123fffff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90a157-ddab-403b-9825-f8c4a6bcde1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled = calculate_band_indices(scaled)\n",
    "Dataset = scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b4340-0375-4e76-a228-44843530483b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### GLCM texture analysis\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6319c-a4e0-42a7-9408-1b131e0220c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 9\n",
    "LEVELS = 32\n",
    "\n",
    "# Input\n",
    "max = scaled.blue.max().values\n",
    "min = scaled.blue.min().values\n",
    "# Scale to 0-LEVELS for GLCM\n",
    "img = ((scaled.blue - min) / (max - min) * (LEVELS - 1)).clip(0, LEVELS - 1).values.astype(np.uint8)\n",
    "\n",
    "# Extract overlapping windows\n",
    "patches = sliding_window_view(img, (WINDOW_SIZE, WINDOW_SIZE))\n",
    "# Shape: (rows, cols, win_y, win_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0972e-bc50-4cbc-92d0-b985ec9dd417",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # Ensure numpy is imported if not already\n",
    "\n",
    "# Assuming 'patches' is a 4D NumPy array with dimensions (y_coords, x_coords, window_y_size, window_x_size)\n",
    "# To get the first patch (at y=0, x=0), you would index it like this:\n",
    "sample_patch_data = patches[0, 0, :, :]\n",
    "\n",
    "# Verify the shape of the extracted sample patch data\n",
    "print(f\"Shape of sample_patch_data: {sample_patch_data.shape}\")\n",
    "\n",
    "# Call glcm_features directly on this 2D sample data\n",
    "sample_result = glcm_features(sample_patch_data)\n",
    "\n",
    "# Print the shape of the result to get the number of features\n",
    "print(f\"Shape of glcm_features output for a single patch: {sample_result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3c616",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use apply_ufunc to vectorize over (row, col) dimensions\n",
    "result = xr.apply_ufunc(\n",
    "    glcm_features,\n",
    "    xr.DataArray(patches, dims=[\"y\", \"x\", \"win_y\", \"win_x\"]),\n",
    "    input_core_dims=[[\"win_y\", \"win_x\"]],\n",
    "    output_core_dims=[[\"feature\"]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[np.float32]\n",
    ")\n",
    "\n",
    "# Add coordinates & names\n",
    "pad = WINDOW_SIZE - 1\n",
    "result = result.assign_coords({\n",
    "    \"y\": scaled.y[: -pad],\n",
    "    \"x\": scaled.x[: -pad],\n",
    "    \"feature\": [\"contrast\", \"homogeneity\", \"energy\", \"ASM\", \"correlation\", \"mean\", \"entropy\"]\n",
    "})\n",
    "\n",
    "result_bands = result.to_dataset(dim=\"feature\")\n",
    "\n",
    "# Combine with original\n",
    "combined = scaled.copy()\n",
    "combined = combined.assign(result_bands)\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8066d07-2200-4a65-a520-0892def7f8c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_combined, mask = all_masks(combined, return_mask = True)\n",
    "mask.odc.explore(vmin=0, vmax=0.3, bands=[\"red\", \"green\", \"blue\"], crs=\"EPSG:3832\", name=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db1893-c95d-484b-acd1-6335ebb9ed90",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_combined.odc.explore(vmin=0, vmax=0.3, bands=[\"red\", \"green\", \"blue\"], crs=\"EPSG:3832\", name=site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd17e13-a9d8-4c1a-9f4f-37caea2ca87e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Postcard csv\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c58091-c716-40fd-9007-8ff22bfbe631",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reproject training data to the GeoMAD CRS and convert to xarray\n",
    "training_reprojected = training.to_crs(masked_combined.odc.crs)\n",
    "training_da = training_reprojected.assign(\n",
    "    x=training_reprojected.geometry.x, y=training_reprojected.geometry.y\n",
    ").to_xarray()\n",
    "\n",
    "# Extract training values from the masked dataset\n",
    "training_values = (\n",
    "    masked_combined.sel(training_da[[\"x\", \"y\"]], method=\"nearest\")\n",
    "    .squeeze()\n",
    "    .compute()\n",
    "    .to_pandas()\n",
    ")\n",
    "training_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d13b52-bdfa-4709-ace8-8bae982060f1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join the training data with the extracted values and remove unnecessary columns\n",
    "training_array = pd.concat([training[\"cc_id\"], training_values], axis=1)\n",
    "\n",
    "# Drop rows where there was no data available\n",
    "training_array = training_array.dropna()\n",
    "\n",
    "# Preview our resulting training array\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3eaf7-7a73-40bb-8539-1d6feb6403f4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(training_array.shape[1], 'total columns')\n",
    "print('columns included', training_array.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c23c6c-bdb9-4db0-8076-499aa1faf6e2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_schema = ['cc_id', 'nir', 'red', 'blue', 'green', 'emad', 'smad', 'bcmad',\n",
    "       'nir08', 'nir09', 'swir16', 'swir22', 'coastal', 'rededge1',\n",
    "       'rededge2', 'rededge3', 'mndwi', 'ndti', 'cai', 'ndvi', 'evi', 'savi',\n",
    "       'ndwi', 'b_g', 'b_r', 'mci', 'ndci', 'ln_bg', 'contrast', 'homogeneity',\n",
    "       'energy', 'ASM', 'correlation', 'mean', 'entropy', 'y', 'x', 'time',\n",
    "       'spatial_ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddafe443-ed4e-4efe-99da-97ff0192cb75",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_array=training_array[standard_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df351b-8dc3-4c3b-9135-a00c35ec4397",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_array=training_array.drop(columns=[\"spatial_ref\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f597a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write the training data to a CSV file\n",
    "training_array.to_csv(f\"training-data/csvs/{version}-training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012f7ef-81cb-4247-a6de-1ffc32373f77",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_array[\"cc_id\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22809951-9e71-46c8-9435-d99b7701ec17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.629084,
   "end_time": "2025-07-27T00:09:21.059478",
   "environment_variables": {},
   "exception": true,
   "input_path": "1-generate-postcard-csv.ipynb",
   "output_path": "automated_notebook_runs/executed_notebooks/nm-serua-26072025_postcard_executed.ipynb",
   "parameters": {
    "input_geojson_path": "training-data/postcards/nm-serua-26072025_postcard.geojson",
    "output_csv_path": "automated_notebook_runs/sampled_data_csvs/nm-serua-26072025_postcard_sampled_data.csv"
   },
   "start_time": "2025-07-27T00:09:15.430394",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}