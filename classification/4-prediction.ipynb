{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718f54c3-6d20-4ed0-9752-e1751e6b84e5",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/nicholasmetherall/digital-earth-pacific-macblue-activities/blob/main/attachments/images/DE_Pacific_banner.JPG?raw=true\" width=\"900\"/>\n",
    "\n",
    "Figure 1.1.a. Jupyter environment + Python notebooks\n",
    "\n",
    "# Digital Earth Pacific Notebook 1 prepare postcard and load data to csv\n",
    "\n",
    "The objective of this notebook is to prepare a geomad postcard for your AOI (masking, scaling and loading additional band ratios and spectral indices) and sampling all the datasets into a csv based on your training data geodataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887498ee",
   "metadata": {},
   "source": [
    "## Step 1.1: Configure the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bda661-ae78-4f82-82b3-e68a5aa32d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import box\n",
    "from pyproj import CRS \n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import joblib\n",
    "from ipyleaflet import basemaps\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import pystac_client\n",
    "from dask.distributed import Client as DaskClient\n",
    "from odc.stac import load, configure_s3_access\n",
    "import planetary_computer\n",
    "from odc.stac import load\n",
    "from pystac.client import Client\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from utils import load_data, scale, calculate_band_indices, apply_mask, mask_land, mask_deeps, mask_elevation, all_masks, glcm_features, do_prediction, probability, output, proba_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2edc9da-3387-495f-b7bc-5e3210259076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload scripts and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2c3e96-d81a-4a01-b638-20cde81d98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm-tulagi-25072025\n"
     ]
    }
   ],
   "source": [
    "# Predefined variable for title and version\n",
    "\n",
    "# Enter your initials\n",
    "initials = \"nm\"\n",
    "\n",
    "# Enter your site name\n",
    "site = \"tulagi\"\n",
    "\n",
    "# Date\n",
    "date = datetime.now()\n",
    "\n",
    "# Make a clean version string\n",
    "version = f\"{initials}-{site}-{date.strftime('%d%m%Y')}\"\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb62e5e-32bf-4ccd-8ac1-8e7c95102d5a",
   "metadata": {},
   "source": [
    "## Step 1.2: Configure STAC access and search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975ca2ac-2484-4d63-8f54-e7370dd8764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = \"https://stac.digitalearthpacific.org\"\n",
    "client = Client.open(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f010cdf-e7ae-4d07-94fb-d33de1758634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Use training data bounds\n",
    "\n",
    "training = gpd.read_file(f\"training-data/{version}_postcard.geojson\")\n",
    "training = training.to_crs(\"EPSG:4326\")\n",
    "min_lon, min_lat, max_lon, max_lat = training.total_bounds\n",
    "\n",
    "bbox = [min_lon, min_lat, max_lon, max_lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a580b2-f7cf-444c-bcd9-fb87088c4f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items in for 2024\n"
     ]
    }
   ],
   "source": [
    "datetime = \"2024\"\n",
    "\n",
    "items = client.search(\n",
    "    collections=[\"dep_s2_geomad\"],\n",
    "    datetime=datetime,\n",
    "    bbox=bbox\n",
    ").item_collection()\n",
    "\n",
    "print(f\"Found {len(items)} items in for {datetime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e2abf4-e303-44bd-9747-e03419a42da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 22MB\n",
      "Dimensions:      (y: 784, x: 762, time: 1)\n",
      "Coordinates:\n",
      "  * y            (y) float64 6kB -1.009e+06 -1.009e+06 ... -1.017e+06 -1.017e+06\n",
      "  * x            (x) float64 6kB 1.124e+06 1.124e+06 ... 1.132e+06 1.132e+06\n",
      "    spatial_ref  int32 4B 3832\n",
      "  * time         (time) datetime64[ns] 8B 2024-01-01\n",
      "Data variables: (12/15)\n",
      "    nir          (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    red          (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    blue         (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    green        (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    emad         (time, y, x) float32 2MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    smad         (time, y, x) float32 2MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    ...           ...\n",
      "    swir16       (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    swir22       (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    coastal      (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    rededge1     (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    rededge2     (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n",
      "    rededge3     (time, y, x) uint16 1MB dask.array<chunksize=(1, 784, 762), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "measurements = [\"nir\", \"red\", \"blue\", \"green\", \"emad\", \"smad\", \"bcmad\", \"green\", \"nir08\", \"nir09\", \"swir16\", \"swir22\", \"coastal\", \"rededge1\", \"rededge2\", \"rededge3\"]\n",
    "data = load_data(\n",
    "    items,\n",
    "    measurements,\n",
    "    bbox,\n",
    ")\n",
    "    \n",
    "# Now you can use the 'data' variable\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ea9480-1232-4e9d-b70e-a87a37242135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41691 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dask_client = DaskClient(n_workers=1, threads_per_worker=16, memory_limit='16GB')\n",
    "configure_s3_access(cloud_defaults=True, requester_pays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f514c9ea-39b8-44bc-a68f-33e632a7c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scale(data)\n",
    "scaled = scaled.compute().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec90a157-ddab-403b-9825-f8c4a6bcde1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = calculate_band_indices(scaled)\n",
    "Dataset = scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b4340-0375-4e76-a228-44843530483b",
   "metadata": {},
   "source": [
    "### GLCM texture analysis\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc6319c-a4e0-42a7-9408-1b131e0220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 9\n",
    "LEVELS = 32\n",
    "\n",
    "# Input\n",
    "max = scaled.blue.max().values\n",
    "min = scaled.blue.min().values\n",
    "# Scale to 0-LEVELS for GLCM\n",
    "img = ((scaled.blue - min) / (max - min) * (LEVELS - 1)).clip(0, LEVELS - 1).values.astype(np.uint8)\n",
    "\n",
    "# Extract overlapping windows\n",
    "patches = sliding_window_view(img, (WINDOW_SIZE, WINDOW_SIZE))\n",
    "# Shape: (rows, cols, win_y, win_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b0972e-bc50-4cbc-92d0-b985ec9dd417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample_patch_data: (9, 9)\n",
      "Shape of glcm_features output for a single patch: (7,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # Ensure numpy is imported if not already\n",
    "\n",
    "# Assuming 'patches' is a 4D NumPy array with dimensions (y_coords, x_coords, window_y_size, window_x_size)\n",
    "# To get the first patch (at y=0, x=0), you would index it like this:\n",
    "sample_patch_data = patches[0, 0, :, :]\n",
    "\n",
    "# Verify the shape of the extracted sample patch data\n",
    "print(f\"Shape of sample_patch_data: {sample_patch_data.shape}\")\n",
    "\n",
    "# Call glcm_features directly on this 2D sample data\n",
    "sample_result = glcm_features(sample_patch_data)\n",
    "\n",
    "# Print the shape of the result to get the number of features\n",
    "print(f\"Shape of glcm_features output for a single patch: {sample_result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use apply_ufunc to vectorize over (row, col) dimensions\n",
    "result = xr.apply_ufunc(\n",
    "    glcm_features,\n",
    "    xr.DataArray(patches, dims=[\"y\", \"x\", \"win_y\", \"win_x\"]),\n",
    "    input_core_dims=[[\"win_y\", \"win_x\"]],\n",
    "    output_core_dims=[[\"feature\"]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[np.float32]\n",
    ")\n",
    "\n",
    "# Add coordinates & names\n",
    "pad = WINDOW_SIZE - 1\n",
    "result = result.assign_coords({\n",
    "    \"y\": scaled.y[: -pad],\n",
    "    \"x\": scaled.x[: -pad],\n",
    "    \"feature\": [\"contrast\", \"homogeneity\", \"energy\", \"ASM\", \"correlation\", \"mean\", \"entropy\"]\n",
    "})\n",
    "\n",
    "result_bands = result.to_dataset(dim=\"feature\")\n",
    "\n",
    "# Combine with original\n",
    "combined_ds = scaled.copy()\n",
    "combined_ds = combined_ds.assign(result_bands)\n",
    "\n",
    "combined_ds\n",
    "combined_ds.odc.explore(vmin=0, vmax=0.3, bands=[\"red\", \"green\", \"blue\"], crs=\"EPSG:3832\", name=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7db0c-88a6-4ac5-a26c-351fb8c74612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All masks\n",
    "masked_scaled, mask = all_masks(combined_ds, return_mask = True)\n",
    "masked_scaled.odc.explore(vmin=0, vmax=0.3, bands=[\"red\", \"green\", \"blue\"], crs=\"EPSG:3832\", name=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ab061-a02f-49d0-9bea-66cb8f541295",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a89e9e-c5ba-46d1-b5ec-a67605ea1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_ds = masked_scaled.drop_vars(\"count\")\n",
    "combined_da = masked_scaled.to_dataarray()\n",
    "combined_da = combined_da.squeeze()#.stack(dims=[\"y\", \"x\"])#.transpose()\n",
    "stacked_arrays_2d = combined_da.stack(new_dim=(\"y\", \"x\")) \n",
    "reordered_data_array = stacked_arrays_2d.transpose('new_dim', 'variable')\n",
    "stacked_arrays_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any infinities with NaN\n",
    "stacked_arrays_2d = stacked_arrays_2d.where(stacked_arrays_2d != float(\"inf\"))\n",
    "stacked_arrays_2d = stacked_arrays_2d.where(stacked_arrays_2d != float(\"-inf\"))\n",
    "\n",
    "# Replace any NaN values with 0\n",
    "df = stacked_arrays_2d.squeeze().fillna(0).transpose().to_pandas()\n",
    "\n",
    "# Remove the all-zero rows\n",
    "zero_mask = (df == 0).all(axis=1)  # Creates a boolean Series\n",
    "non_zero_df = df.loc[~zero_mask]  # Filters out all-zero rows\n",
    "\n",
    "# Create a new array to hold the predictions\n",
    "full_pred = pd.Series(np.nan, index=df.index)\n",
    "\n",
    "reordered_data_array = stacked_arrays_2d.transpose('new_dim', 'variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca6a0f-27dd-4e63-9277-294319e77766",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0035a7f-f45b-4dfa-af71-e79d2c092d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b41ae-6e6a-423c-9ea3-4bbc810be2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa22f60-eccd-448a-8663-af907cfe8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"models/nm-25072025-test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51de5b2-e90e-480a-8855-332f2fca7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes\n",
    "predicted = model.predict(reordered_data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbaea7e-b8e2-41f5-8c32-afab85cd2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape back to the original 2D array\n",
    "reordered_data_array = predicted.reshape(len(masked_scaled.y), len(masked_scaled.x))\n",
    "\n",
    "# Convert to an xarray again, because it's easier to work with\n",
    "predicted_da = xr.DataArray(\n",
    "    reordered_data_array, coords={\"y\": masked_scaled.y, \"x\": masked_scaled.x}, dims=[\"y\", \"x\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b8ead-d45c-4e13-9b90-12a091cd9b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_da.dtype)  # Check the dtype of your DataArray\n",
    "predicted_da = predicted_da.astype('float32')  # Convert to float32\n",
    "\n",
    "# Check for NaN values\n",
    "if np.isnan(predicted_da).any():\n",
    "    print(\"NaN values found in the data\")\n",
    "    # Handle NaN values, e.g. by filling them\n",
    "    predicted_da = predicted_da.fillna(0)  # Replace NaN with 0 or appropriate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e18c1-2186-4b91-baa5-0fc5dd0494fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_scaled = masked_scaled.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4edbf1-712d-4cf8-975a-419939e15fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_scaled = masked_scaled.drop_vars(\"count\")\n",
    "\n",
    "predicted = do_prediction(masked_scaled, model)\n",
    "predicted\n",
    "# predicted.odc.explore(cmap=c_map, tiles=basemaps.Esri.WorldImagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d229ca-0909-4a79-91de-cc5fbefc195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1c562-ed14-4aa0-a83d-8f0b5a970938",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.where(mask)\n",
    "# `prediction` is your predicted class array# `mask` is your boolean mask, where True means masked\n",
    "nodata_value = 0  # or -9999, or whatever you chooseprediction_with_mask = prediction.copy()\n",
    "predicted['mask'] = nodata_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2475921-c9b7-4757-a4b4-615f0ec0f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0620c-df0b-4fcf-8878-2dcc3a3b5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695abea-1b7d-43e6-a862-8cecb7d3a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "classes = [\n",
    "    [1, \"sediment\", \"#8c8c8c\"],\n",
    "    [2, \"sand\", \"#fedd24\"],\n",
    "    [3, \"rubble\", \"#f8ffb4\"],\n",
    "    [4, \"seagrass\", \"#6df7dc\"],\n",
    "    [5, \"seaweed\", \"#b9df6f\"],\n",
    "    [6, \"coral\", \"#a011c3\"],\n",
    "    [7, \"rock\", \"#804600\"],\n",
    "    [8, \"deeps\", \"#011b61\"],\n",
    "    [9, \"mangrove\", \"#086a39\"],\n",
    "    [10, \"land\", \"#ffffff\"],\n",
    "]\n",
    "\n",
    "seagrass_value = 4\n",
    "values_list = [c[0] for c in classes]\n",
    "color_list = [c[2] for c in classes]\n",
    "\n",
    "# Build a listed colormap.\n",
    "c_map = colors.ListedColormap(color_list)\n",
    "bounds = values_list + [14]\n",
    "norm = colors.BoundaryNorm(bounds, c_map.N)\n",
    "\n",
    "# predicted_da.plot.imshow(cmap=c_map, norm=norm, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10249532-b1b5-4c5a-b1e9-c32bfd0a2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "seagrass_extent = output(predicted, seagrass_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4231224-cc48-4d7b-b05f-a82d216abe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seagrass_extent.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dac372-a410-4c35-a872-758d9bcc7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269355c6-54d6-4cbc-a0c2-4c4e41773eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_output = probability(\n",
    "    masked_scaled,\n",
    "    model, \n",
    "    ['nir', 'red', 'blue', 'green', 'emad', 'smad', 'bcmad', 'nir08', 'nir09', 'swir16', 'swir22', 'coastal', 'rededge1', 'rededge2', 'rededge3', 'mndwi', 'ndti', 'cai', 'ndvi', 'evi', 'savi', 'ndwi', 'b_g', 'b_r', 'mci', 'ndci', 'ln_bg', 'contrast', 'homogeneity', 'energy', 'ASM', 'correlation', 'mean', 'entropy'],\n",
    "    seagrass_value,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5645e90-09e6-4261-b2fe-0c0e93c2144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_output.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7cf5b-ca77-4057-b475-e6a5a5f92f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17774e0e-f8aa-4f13-abdb-c85a81e10f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cert = probability_output.where(probability_output > 60)\n",
    "high_cert.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39321b2-29fb-4cb4-a55a-8c68217ee85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seagrass_extent = proba_binary(probability_output, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47178157-65dd-48ad-9805-a1d9ea7a03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seagrass_extent.odc.write_cog(f\"predictions/{version}-prediction.tif\", crs=\"EPSG:3832\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8fe30-645f-43f8-bb90-e217972c574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_for_0 = '#8c8c8c'   # Grey for '<60% probability seagrass'\n",
    "color_for_1 = '#33ffe0'   # Cyan for '>60% probability seagrass'\n",
    "color_for_nodata = '#00000000' # Transparent white\n",
    "\n",
    "# For interactive `odc.explore`, you often want nodata to be truly transparent:\n",
    "transparent_nodata_color = (0, 0, 0, 0) # RGBA tuple (Red, Green, Blue, Alpha)\n",
    "\n",
    "# Create a list of colors in the order of your desired bins\n",
    "# The order is crucial: [color for 0, color for 1, color for 255]\n",
    "custom_colors_static = [color_for_0, color_for_1, color_for_nodata]\n",
    "custom_colors_explore = [color_for_0, color_for_1, transparent_nodata_color]\n",
    "\n",
    "\n",
    "# 2. Create the ListedColormap\n",
    "binary_cmap_static = colors.ListedColormap(custom_colors_static)\n",
    "binary_cmap_explore = colors.ListedColormap(custom_colors_explore)\n",
    "\n",
    "\n",
    "# 3. Define the boundaries for your values\n",
    "# For values: 0, 1, 255\n",
    "# Bounds needed: 0, 0.5, 1.5, 255.5\n",
    "# - Values in [0, 0.5) will get the first color (for 0)\n",
    "# - Values in [0.5, 1.5) will get the second color (for 1)\n",
    "# - Values in [1.5, 255.5) will get the third color (for 255)\n",
    "bounds = [0, 0.5, 1.5, 255.5]\n",
    "\n",
    "\n",
    "# 4. Create the BoundaryNorm\n",
    "# `binary_cmap.N` automatically gives the number of colors in your colormap (which is 3 here)\n",
    "binary_norm = colors.BoundaryNorm(bounds, binary_cmap_static.N)\n",
    "\n",
    "\n",
    "# --- Plotting the result using .plot.imshow() for a static plot ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "seagrass_extent.plot.imshow(\n",
    "    cmap=binary_cmap_static, # Use the static colormap\n",
    "    norm=binary_norm,\n",
    "    add_colorbar=True,\n",
    "    cbar_kwargs={'ticks': [0, 1, 255], 'label': 'Seagrass Presence (0: Other, 1: Seagrass, 255: NoData)'}\n",
    ")\n",
    "plt.title(\"Binary Seagrass Extent Map (Static Plot)\")\n",
    "plt.xlabel(\"X Coordinate\")\n",
    "plt.ylabel(\"Y Coordinate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3d614-a6d1-4e0b-80aa-d997fca8285d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
