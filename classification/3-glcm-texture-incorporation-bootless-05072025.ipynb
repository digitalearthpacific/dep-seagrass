{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718f54c3-6d20-4ed0-9752-e1751e6b84e5",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/nicholasmetherall/digital-earth-pacific-macblue-activities/blob/main/attachments/images/DE_Pacific_banner.JPG?raw=true\" width=\"900\"/>\n",
    "Figure 1.1.a. Jupyter environment + Python notebooks\n",
    "\n",
    "### Digital Earth Pacific Notebook 1 prepare postcard and load data to csv\n",
    "\n",
    "The objective of this notebook is to prepare a geomad postcard for your AOI (masking, scaling and loading additional band ratios and spectral indices) and sampling all the datasets into a csv based on your training data geodataframe.\n",
    "\n",
    "Step 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bda661-ae78-4f82-82b3-e68a5aa32d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from dask.distributed import Client as DaskClient\n",
    "from odc.stac import load, configure_s3_access\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import folium\n",
    "from datetime import datetime\n",
    "import utils\n",
    "from utils import scale\n",
    "from utils import calculate_band_indices\n",
    "from utils import load_data\n",
    "from utils import patchwise_glcm_feature\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import odc.geo.xr\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from shapely.geometry import box\n",
    "import skimage.feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage import data\n",
    "from skimage.util import view_as_windows\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2c3e96-d81a-4a01-b638-20cde81d98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm-bootless-04-07-2025\n"
     ]
    }
   ],
   "source": [
    "# Predefined variable for title and version\n",
    "\n",
    "# Enter your initials\n",
    "initials = \"nm\"\n",
    "# Enter your site name\n",
    "site = \"bootless\"\n",
    "# Date\n",
    "date = datetime.now()\n",
    "date = date.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "version = initials+'-'+site+'-'+date\n",
    "\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb62e5e-32bf-4ccd-8ac1-8e7c95102d5a",
   "metadata": {},
   "source": [
    "Define catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975ca2ac-2484-4d63-8f54-e7370dd8764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = \"https://stac.digitalearthpacific.org\"\n",
    "client = Client.open(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f010cdf-e7ae-4d07-94fb-d33de1758634",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use tdata bounds\n",
    "\n",
    "gdf = gpd.read_file(\"training-data/bootless_bay.geojson\")\n",
    "gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "min_lon, min_lat, max_lon, max_lat = gdf.total_bounds\n",
    "bbox = [min_lon, min_lat, max_lon, max_lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af7f3ef-b395-4d6f-a2cc-6f10bb29ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use bounding box\n",
    "\n",
    "# min_lon = 160.08855\n",
    "# min_lat = -9.12915\n",
    "# max_lon = 160.17137\n",
    "# max_lat = -9.08003\n",
    "\n",
    "# bbox = [min_lon, min_lat, max_lon, max_lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a580b2-f7cf-444c-bcd9-fb87088c4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime=\"2024\"\n",
    "items = list(client.search(collections=[\"dep_s2_geomad\"], datetime=datetime, bbox=bbox).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535a9993-925b-4b26-86ae-5a3509f8cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac import Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73707fb-291d-430c-8681-1e8a58772785",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = Collection.from_file(\"https://stac.digitalearthpacific.org/collections/dep_s2_geomad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f514c9ea-39b8-44bc-a68f-33e632a7c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\n",
    "        items,\n",
    "        measurements=[\n",
    "            \"nir\", \"red\", \"blue\", \"green\", \"emad\", \"smad\", \n",
    "            \"bcmad\", \"count\", \"green\", \"nir08\", \n",
    "            \"nir09\", \"swir16\", \"swir22\", \"coastal\",\n",
    "            \"rededge1\", \"rededge2\", \"rededge3\", \n",
    "        ],\n",
    "        bbox=bbox,\n",
    "        chunks={\"x\": 2048, \"y\": 2048},\n",
    "        groupby=\"solar_day\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65210110-ac89-4064-bd42-26c29158f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 43365 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dask_client = DaskClient(n_workers=1, threads_per_worker=16, memory_limit='16GB')\n",
    "configure_s3_access(cloud_defaults=True, requester_pays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fe2fc21-d4f7-4260-b1fe-5c759fd368d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaled = (data.where(data != 0) * 0.0001).clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ccfec6-bc85-48a4-83eb-a7c2db3b1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mndwi = (scaled[\"green\"]-scaled[\"swir16\"])/(scaled[\"green\"]+scaled[\"swir16\"])\n",
    "## Moderate land mask\n",
    "# mndwi_land_mask = mndwi > 0\n",
    "mndwi_land_mask = mndwi > -1.5\n",
    "clipped_ds = scaled.where(mndwi_land_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb613c4-f781-4bc5-83b9-9373cccfbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndti = (clipped_ds[\"red\"]-clipped_ds[\"green\"])/(clipped_ds[\"red\"]+clipped_ds[\"green\"])\n",
    "ndti_mask = ndti < 0.2\n",
    "clipped_ds = clipped_ds.where(ndti_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1037c821-2f7e-4c32-8a97-20af2d0bd08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nir = clipped_ds['nir']\n",
    "\n",
    "# Moderate land mask\n",
    "# nir_mask = nir < 0.085\n",
    "\n",
    "# Conservative land mask\n",
    "nir_mask = nir < 0.8\n",
    "clipped_ds = clipped_ds.where(nir_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f82059f-f625-468e-9299-1cae9a3d5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate other band ratios and indices\n",
    "cai = (clipped_ds[\"coastal\"]-clipped_ds[\"blue\"])/( clipped_ds[\"coastal\"]+ clipped_ds[\"blue\"]) #coastal aerosol index\n",
    "ndvi = (clipped_ds[\"nir\"]-clipped_ds[\"red\"])/( clipped_ds[\"nir\"]+ clipped_ds[\"red\"]) #vegetation index (NDVI)\n",
    "evi = ((2.5*clipped_ds[\"nir\"]-clipped_ds[\"red\"])/(clipped_ds[\"nir\"]+(6*clipped_ds[\"red\"])-(7.5*clipped_ds[\"blue\"])+1)) # enhanced vegetation index\n",
    "savi = (clipped_ds[\"nir\"]-clipped_ds[\"red\"])/(clipped_ds[\"nir\"]+clipped_ds[\"red\"]) # soil adjusted vegetation index\n",
    "ndwi = (clipped_ds[\"green\"]-clipped_ds[\"nir\"])/(clipped_ds[\"green\"]+clipped_ds[\"nir\"]+0.428)*(1+0.428) #water index (NDWI)\n",
    "b_g = (clipped_ds[\"blue\"])/(clipped_ds[\"green\"]) #blue to green ratio\n",
    "b_r = (clipped_ds[\"blue\"])/(clipped_ds[\"red\"]) #blue to red ratio\n",
    "mci = (clipped_ds[\"nir\"])/(clipped_ds[\"rededge1\"]) # max chlorophlyll index (MCI)\n",
    "ndci = (clipped_ds[\"rededge1\"]-clipped_ds[\"red\"])/(clipped_ds[\"rededge1\"]+clipped_ds[\"red\"]) # normalised difference chlorophyll index (NDCI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a7365c-9581-46a8-bf62-b4fb69834b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_ds['cai'] = cai\n",
    "clipped_ds['ndvi'] = ndvi\n",
    "clipped_ds['evi'] = evi\n",
    "clipped_ds['savi'] = savi\n",
    "clipped_ds['ndwi'] = ndwi\n",
    "clipped_ds['mndwi'] = mndwi\n",
    "clipped_ds['ndti'] = ndti\n",
    "clipped_ds['b_g'] = b_g\n",
    "clipped_ds['b_r'] = b_r\n",
    "clipped_ds['mci'] = mci\n",
    "clipped_ds['ndci'] = ndci\n",
    "\n",
    "# clipped_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "188aaf30-c83f-42c8-96dd-63dab90216cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural log of blue/green\n",
    "clipped_ds[\"ln_bg\"] = np.log(clipped_ds.blue / clipped_ds.green)\n",
    "bg = clipped_ds[\"ln_bg\"]\n",
    "# conservative deep sea mask\n",
    "mask_bg = bg < 0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff2558f8-6a49-4de8-b895-3723437a3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_masks = (mndwi_land_mask+ndti_mask+nir_mask+mask_bg)\n",
    "all_masks = (mndwi_land_mask+ndti_mask+nir_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b4340-0375-4e76-a228-44843530483b",
   "metadata": {},
   "source": [
    "### GLCM texture analysis\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "119c75bb-c356-4b99-bb97-34570a46d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_image = clipped_ds.to_dataarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "753726d5-e420-484d-b7b5-cea6a381a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_image = texture_image.where(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d804796-b6ff-42c5-b037-30a496e35a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_blue = clipped_ds['blue'].values  # Convert to numpy array for GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b4f1da6-ee2c-47c9-a808-f4d5f787ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected image shape: (490, 262)\n"
     ]
    }
   ],
   "source": [
    "# Remove NaNs (optional, depending on your data)\n",
    "image_blue = np.nan_to_num(image_blue, nan=0)\n",
    "\n",
    "# Normalize to 0â€“255 and convert to uint8\n",
    "image_uint8 = ((image_blue - image_blue.min()) / (image_blue.max() - image_blue.min()) * 255).astype('uint8')\n",
    "\n",
    "image_uint8 = image_uint8[0, :, :]  # Use the first band/slice\n",
    "print(\"Selected image shape:\", image_uint8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f059b409-bbfc-426a-9959-0cd916a3a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcard_crs = clipped_ds.rio.crs\n",
    "postcard_transform = clipped_ds.rio.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4d2e04a-0918-4550-aab8-2c7b7d830d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_image(img):\n",
    "#     image_blue_min = np.nanmin(image_blue)\n",
    "#     image_blue_max = np.nanmax(image_blue)\n",
    "#     if image_blue_max == image_blue_min:\n",
    "#         # All pixels are the same, return a zero array\n",
    "#         return np.zeros_like(image_blue, dtype='uint8')\n",
    "#     arr = (image_blue - image_blue_min) / (image_blue_max - image_blue_min)\n",
    "#     arr = np.clip(arr, 0, 1)  # ensure no negatives or >1 due to rounding\n",
    "#     arr = (arr * 255).astype('uint8')\n",
    "#     return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57634852-090d-4e36-bff6-372fab4b4d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final image_uint8 shape: (490, 262)\n",
      "Final image_uint8 dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "image_uint8 = np.nan_to_num(image_uint8, nan=0)\n",
    "image_uint8 = np.squeeze(image_uint8)\n",
    "image_uint8 = np.ascontiguousarray(image_uint8)\n",
    "image_uint8 = image_uint8.astype('uint8')\n",
    "print(\"Final image_uint8 shape:\", image_uint8.shape)\n",
    "print(\"Final image_uint8 dtype:\", image_uint8.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62d1e4a9-1217-42f7-9dc0-65472a8efb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 262)\n"
     ]
    }
   ],
   "source": [
    "# Remove all dimensions of size 1\n",
    "image2d = np.squeeze(image_blue)\n",
    "# OR, if you want to be explicit:\n",
    "image2d = image_blue[0, :, :]  # Select first band\n",
    "print(image2d.shape)  # Should be (147, 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944c825-9716-4cbc-a62c-89fdf50389bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = patchwise_glcm_feature(\n",
    "    image_uint8, \n",
    "    window_size=7, \n",
    "    levels=256\n",
    ")\n",
    "\n",
    "# Visualize the features\n",
    "plt.figure(figsize=(15, 4))\n",
    "for idx, (name, fmap) in enumerate(features.items()):\n",
    "    plt.subplot(1, len(features), idx+1)\n",
    "    plt.imshow(fmap, cmap='viridis')\n",
    "    plt.title(name.capitalize())\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e31a2-ab52-41e7-acf1-e987edf5d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368ac0a-d33e-423f-96a3-f2ffc0b68962",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_ds=clipped_ds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bda0af-a73b-4291-95c5-cbf32b751048",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, arr in features.items():\n",
    "    clipped_ds[f'glcm_{name}'] = xr.DataArray(\n",
    "        arr,\n",
    "        dims=('y', 'x'),\n",
    "        coords={'y': clipped_ds['y'], 'x': clipped_ds['x']},\n",
    "        name=f'glcm_{name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199f760-06b9-4b10-9758-ef165b18f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd17e13-a9d8-4c1a-9f4f-37caea2ca87e",
   "metadata": {},
   "source": [
    "### Postcard csv\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4dac9-1159-49c0-bb55-dd0f333fc9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training data\n",
    "gdf = gpd.read_file(\"training-data/bootless_bay.geojson\")\n",
    "gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "# gdf.explore(column=\"cc_id\", legend=True)\n",
    "clipped_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52e061-4293-445a-a258-7ce0e42b1552",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_ds = clipped_ds.drop_vars('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c4548-4f96-4f6c-a672-b02907c80736",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcard = clipped_ds#.where(all_masks)\n",
    "# postcard =clipped_ds.to_array(dim=\"band\")\n",
    "# First transform the training points to the same CRS as the data\n",
    "training = gdf.to_crs(postcard.odc.geobox.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadaed5d-6d2e-47f3-9b94-f857846d4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training.columns)\n",
    "training=training.drop(columns=['date', 'uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e977f73-9f9b-41e1-8a1f-8eaaa1e622da",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c58091-c716-40fd-9007-8ff22bfbe631",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_da = training.assign(x=training.geometry.x, y=training.geometry.y).to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3a631-4b48-4d94-8b5d-557cb9ccf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_values = (\n",
    "    postcard.sel(training_da[[\"x\", \"y\"]], method=\"nearest\").squeeze().compute().to_pandas()\n",
    ")\n",
    "training_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d13b52-bdfa-4709-ace8-8bae982060f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the training data with the extracted values and remove unnecessary columns\n",
    "training_array = pd.concat([training[\"cc_id\"], training_values], axis=1)\n",
    "# Drop rows where there was no data available\n",
    "training_array = training_array.dropna()\n",
    "# Preview our resulting training array\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac914a8-93f1-41b5-896f-5ed8f835ec7c",
   "metadata": {},
   "source": [
    "### Notebook 2 - Train Random Forest Machine Learning (ML) Model\n",
    "\n",
    "Combine the csv geodataframes from notebook 1 into a single csv to train the machine learning model\n",
    "\n",
    "Step 2.1. Concatenating all postcard dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f0f3f-fde8-47ba-b097-cb4251d331b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcard_df = training_array\n",
    "postcard_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4526bd5-dd3e-4198-8024-8e022b9bca49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# postcard_df.columns\n",
    "# postcard_df = postcard_df.drop(columns=[\"spatial_ref\", \"time\", \"field_1\", \"y\", \"x\"])\n",
    "# postcard_df = postcard_df.drop(columns=[\"field_1\"])\n",
    "postcard_df = postcard_df.drop(columns=[\"y\", \"x\", \"spatial_ref\", \"time\"])\n",
    "# postcard_df = postcard_df.drop(columns=[\"time\"])\n",
    "postcard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749274b8-1c74-4d2e-9982-e047e0fd9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcard_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15570a-e3df-4d7c-a4be-f6e6bf9e9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(postcard_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6b087-916a-4d40-ad03-3604b7ceacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcard_df.to_csv(\"training-data/\" + str(version) + \"35_params_tdata_04072025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75fa92-31d0-40c0-bda5-5559ee3e0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.read_csv(\"training-data/\" + str(version) + \"35_params_tdata_04072025.csv\")\n",
    "\n",
    "joined_df = joined_df.drop(columns=[\"Unnamed: 0\"])\n",
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554675fa-10ac-4a85-af85-6fcbe0e08fec",
   "metadata": {},
   "source": [
    "Step 2.2. Train the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb383db9-049b-461c-a2e8-64aa2b56d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classes are the first column\n",
    "classes = np.array(postcard_df)[:, 0]\n",
    "\n",
    "# The observation data is everything after the second column\n",
    "observations = np.array(postcard_df)[:, 1:]\n",
    "\n",
    "# Create a model...\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# ...and fit it to the data\n",
    "model = classifier.fit(observations, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c19ec-6a63-4424-a85b-63d58f934e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically create the filename with f-string\n",
    "file_path = f\"models/{version}-test.model\"\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e53d7-b8da-484a-ac35-43c33c0d0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcard_params = postcard_df.columns[1:]\n",
    "print(postcard_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47386cf8-465e-4d8c-94ae-90c80aa70a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifier.feature_importances_\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    'param': postcard_params,  # Use the list directly\n",
    "    'importance': importances,  # Use the list directly\n",
    "}\n",
    "importance_df = pd.DataFrame(data)\n",
    "\n",
    "importance_df[\"%\"] = (importance_df[\"importance\"]*100)\n",
    "\n",
    "sorted_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "sorted_df.to_csv(f\"{version}_importance_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc05154-5455-42ce-b729-dccf9bbd1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fda77-1f48-456b-9bb3-102c1a9837a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156cfb8-2b84-46b4-bc88-146140dba3b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to a stacked array of observations\n",
    "# stacked_arrays = stacked_arrays.squeeze()\n",
    "stacked_arrays = postcard.squeeze()#.stack(dims=[\"y\", \"x\"])#.transpose()\n",
    "stacked_arrays = stacked_arrays.to_dataarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08af77-6d58-4be2-bd26-f8aa5e090897",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55903c41-86fd-4efc-8bf0-58fbf77e4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_arrays_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a45c5e-dcc1-480a-82f1-83d2f34f321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_arrays_2d = stacked_arrays.stack(new_dim=(\"y\", \"x\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44911ef0-cffa-4b34-831d-db467acf4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_data_array = stacked_arrays_2d.transpose('new_dim', 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c52b2-dce2-4a81-9181-922baeaad57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_arrays = stacked_arrays.reshape(-1, 26)\n",
    "stacked_arrays_2d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5c486-3ca6-46e3-83ad-1a35f6a860c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_arrays_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f5972-8380-462c-9db8-65dc872e04c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a stacked array of observations\n",
    "# stacked_arrays_2d = stacked_arrays_2d.to_array().stack(dims=[\"y\", \"x\"])\n",
    "\n",
    "# Replace any infinities with NaN\n",
    "stacked_arrays_2d = stacked_arrays_2d.where(stacked_arrays_2d != float(\"inf\"))\n",
    "stacked_arrays_2d = stacked_arrays_2d.where(stacked_arrays_2d != float(\"-inf\"))\n",
    "\n",
    "# Replace any NaN values with 0\n",
    "df = stacked_arrays_2d.squeeze().fillna(0).transpose().to_pandas()\n",
    "\n",
    "# Remove the all-zero rows\n",
    "zero_mask = (df == 0).all(axis=1)  # Creates a boolean Series\n",
    "non_zero_df = df.loc[~zero_mask]  # Filters out all-zero rows\n",
    "\n",
    "# Create a new array to hold the predictions\n",
    "full_pred = pd.Series(np.nan, index=df.index)\n",
    "\n",
    "reordered_data_array = stacked_arrays_2d.transpose('new_dim', 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff461ee-9ce3-459f-8961-7c6ceb317364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes\n",
    "predicted = model.predict(reordered_data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f59ca-60fc-4c69-b861-5635352584bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape back to the original 2D array\n",
    "reordered_data_array = predicted.reshape(len(postcard.y), len(postcard.x))\n",
    "\n",
    "# Convert to an xarray again, because it's easier to work with\n",
    "predicted_da = xr.DataArray(\n",
    "    reordered_data_array, coords={\"y\": postcard.y, \"x\": postcard.x}, dims=[\"y\", \"x\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc74bda-3e32-4dc8-9b65-ea75d02368c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_da.dtype)  # Check the dtype of your DataArray\n",
    "predicted_da = predicted_da.astype('float32')  # Convert to float32\n",
    "\n",
    "# Check for NaN values\n",
    "if np.isnan(predicted_da).any():\n",
    "    print(\"NaN values found in the data\")\n",
    "    # Handle NaN values, e.g. by filling them\n",
    "    predicted_da = predicted_da.fillna(0)  # Replace NaN with 0 or appropriate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0be12-64b2-4187-a7c5-ff0f98e27d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a03fa-a63f-4079-8cd0-8356581642a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "classes = [\n",
    "    [1, \"sediment\", \"#8c8c8c\"],\n",
    "    [2, \"sand\", \"#fedd24\"],\n",
    "    [3, \"rubble\", \"#f8ffb4\"],\n",
    "    [4, \"seagrass\", \"#6df7dc\"],\n",
    "    [5, \"seaweed\", \"#b9df6f\"],\n",
    "    [6, \"coral\", \"#a011c3\"],\n",
    "    [7, \"rock\", \"#804600\"],\n",
    "    [8, \"deeps\", \"#011b61\"],\n",
    "    [9, \"mangrove\", \"#086a39\"],\n",
    "    [10, \"land\", \"#ffffff\"],\n",
    "]\n",
    "\n",
    "values_list = [c[0] for c in classes]\n",
    "color_list = [c[2] for c in classes]\n",
    "\n",
    "# Build a listed colormap.\n",
    "c_map = colors.ListedColormap(color_list)\n",
    "bounds = values_list + [14]\n",
    "norm = colors.BoundaryNorm(bounds, c_map.N)\n",
    "\n",
    "predicted_da.plot.imshow(cmap=c_map, norm=norm, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b357a9-ed34-4160-b3f3-19fed21b0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_da.odc.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd913d8-dd46-4ed8-8ab3-2bbcdac6bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue where not all masks are being included - only land but not surf / also strange effect on side\n",
    "predicted_da = predicted_da.where(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156916b-3364-43d2-a674-0c2c69bf180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_da.odc.explore(cmap=c_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7ff25-34d8-4b39-a103-d2ccaee2b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue where not all masks are being included - only land but not surf / also strange effect on side\n",
    "predicted_da = predicted_da.where(bg < 0.2)\n",
    "predicted_da.odc.explore(cmap=c_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db6a76-2043-46d4-a301-78fc0a8d301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_da.odc.write_cog(f\"{version}.tiff\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223af22-de3d-4f5f-b358-c0c9d56feb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ba353-d4fc-4cc2-8b94-9ff40ce3d26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
